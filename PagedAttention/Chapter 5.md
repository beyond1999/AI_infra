éå¸¸æ£’ğŸ‘
 é‚£æˆ‘ä»¬è¿›å…¥ **ç¬¬ 5 ç« ï¼šPagedAttention çš„ Kernel å®ç°ä¸ FlashAttention çš„å…³ç³»**ã€‚
 è¿™æ˜¯ PagedAttention æœ€â€œç¡¬æ ¸â€çš„éƒ¨åˆ† â€”â€” å¦‚ä½•è®©åˆ†é¡µåŒ–çš„ KV Cache ä¾ç„¶èƒ½åœ¨ GPU ä¸Šè·‘å¾—é£å¿«ã€‚

------

# ğŸ§® ç¬¬ 5 ç« ï¼šPagedAttention Kernel å®ç°åŸç†

PagedAttention çš„æ ¸å¿ƒæŒ‘æˆ˜æ˜¯ï¼š

> **åœ¨åˆ†é¡µå†…å­˜ç»“æ„ä¸‹ï¼Œä»ç„¶ä¿æŒé«˜ååã€é«˜å¸¦å®½çš„æ³¨æ„åŠ›è®¡ç®—æ€§èƒ½ã€‚**

ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬è¦è®©ã€Œä¸è¿ç»­çš„ K/Vã€åœ¨ GPU ä¸Šçš„è®¿é—®å‡ ä¹ä¸æ¯”è¿ç»­å­˜å‚¨æ…¢ã€‚

------

## ğŸ§© 5.1 ä¼ ç»Ÿæ³¨æ„åŠ›è®¡ç®—å›é¡¾

å¯¹äºä¸€ä¸ªåºåˆ—é•¿åº¦ ( L )ï¼Œæ³¨æ„åŠ›è®¡ç®—æ˜¯ï¼š

[
 \text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d}}\right)V
 ]

å…¶ä¸­ï¼š

- ( Q ) = å½“å‰æ­¥ query
- ( K,V ) = å†å²ç¼“å­˜çš„ key/value

ä¼ ç»Ÿå®ç°éœ€è¦è®¿é—®å½¢å¦‚ï¼š

```
K, V shape = [num_heads, seq_len, head_dim]
```

é—®é¢˜æ˜¯ï¼šPagedAttention çš„ K/V ä¸å†æ˜¯è¿ç»­çš„ `[0:L]`ï¼Œè€Œæ˜¯åˆ†å¸ƒåœ¨å¤šä¸ª page/block é‡Œã€‚

------

## âš™ï¸ 5.2 åˆ†é¡µåŒ–çš„ K/V å­˜å‚¨ç»“æ„

PagedAttention çš„å…¨å±€ KV Pool å½¢çŠ¶ï¼š

```
K/V: [num_layers, num_heads, num_blocks, block_size, head_dim]
```

æ¯ä¸ªåºåˆ—æœ‰è‡ªå·±çš„é¡µè¡¨ï¼š

```
page_table = [12, 45, 78, 91]   # æ˜ å°„åˆ°ç‰©ç†block
```

ç›®æ ‡æ˜¯ï¼š

- ä»è¿™ 4 ä¸ª block ä¸­ gather å‡ºçœŸå®çš„ token æ•°æ®ï¼›
- åœ¨ kernel å†…éƒ¨æ‹¼æˆé€»è¾‘é¡ºåºï¼›
- æ‰§è¡Œ ( QK^T )ã€softmaxã€( *V )ã€‚

------

## ğŸš€ 5.3 GPU kernel çš„æ€»ä½“æ€è·¯

PagedAttention çš„ kernel æ˜¯ä¸€ç§ **â€œç´¢å¼•æ„ŸçŸ¥å‹æ‰¹é‡æ³¨æ„åŠ›ç®—å­â€**ï¼Œå¤§è‡´åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š

### Step 1ï¸âƒ£ æ„å»ºç´¢å¼•è¡¨ï¼ˆIndex Listï¼‰

åœ¨ host ä¾§ï¼Œæ ¹æ® batch ä¸­æ‰€æœ‰åºåˆ—çš„é¡µè¡¨ï¼Œç”Ÿæˆï¼š

```text
block_indices = [12, 45, 78, 91, 13, 46, 14, 47, 79, ...]
block_offsets = [0, 16, 32, 48, ...]   # é€»è¾‘æ‹¼æ¥åç§»
```

### Step 2ï¸âƒ£ GPU ç«¯ gather K/V æ•°æ®

GPU å†…æ ¸å¯åŠ¨æ—¶ï¼Œæ¯ä¸ªçº¿ç¨‹å—è´Ÿè´£è‹¥å¹²ä¸ª query tokenï¼š

```cpp
for (int b = 0; b < num_blocks; ++b) {
    int block_id = block_indices[b];
    K_block = load_from(KV_pool + block_id * block_stride);
    V_block = load_from(KV_pool + block_id * block_stride);
    // æ‹¼æ¥åˆ°è¿ç»­ç¼“å†²åŒº (æˆ–ç›´æ¥è®¡ç®—)
}
```

> âš¡ï¸ ä¼˜åŒ–ç‚¹ï¼šæ¯ä¸ª block æ˜¯è¿ç»­çš„ã€å¤§å°å›ºå®šï¼Œå› æ­¤å¯ä»¥é«˜æ•ˆ `ldmatrix` / `cp.async` è½½å…¥ã€‚

### Step 3ï¸âƒ£ è®¡ç®— Attention(Q, K, V)

- å°†æ‰€æœ‰ K/V block é€»è¾‘æ‹¼æ¥ï¼›
- æ‰§è¡Œæ ‡å‡† attention è®¡ç®—ï¼›
- æˆ–è€…è°ƒç”¨ FlashAttention å†…æ ¸ï¼ˆä¸‹èŠ‚è§£é‡Šï¼‰ã€‚

------

## ğŸ§® 5.4 FlashAttention ä¸ PagedAttention çš„å…³ç³»

| å±‚é¢     | FlashAttention                   | PagedAttention               |
| -------- | -------------------------------- | ---------------------------- |
| ä¼˜åŒ–ç›®æ ‡ | å‡å°‘æ˜¾å­˜ IO                      | å‡å°‘æ˜¾å­˜ç¢ç‰‡                 |
| ä¼˜åŒ–å•ä½ | tileï¼ˆçŸ©é˜µå—ï¼‰                   | page/blockï¼ˆæ˜¾å­˜å—ï¼‰         |
| å†…æ ¸å†…éƒ¨ | æµå¼ softmax + block-wise matmul | åˆ†é¡µ gather + batched kernel |
| é…åˆå…³ç³» | Flash åœ¨é¡µå†…éƒ¨åšä¼˜åŒ–             | Paged åœ¨é¡µå¤–éƒ¨è°ƒåº¦ä¼˜åŒ–       |

äºŒè€…å¯ä»¥å®Œç¾å åŠ ï¼š

- PagedAttention è´Ÿè´£**æŠŠåˆ†æ•£åœ¨å„é¡µçš„ KV æ•´ç†æˆé€»è¾‘è¿ç»­çš„è¾“å…¥æµ**ï¼›
- FlashAttention å†…æ ¸è´Ÿè´£**åœ¨ tile çº§åˆ«è¿›è¡Œé«˜é€ŸçŸ©é˜µä¹˜å’Œ softmax ç´¯ç§¯**ã€‚

vLLM å®é™…ä¸Šå°±æ˜¯ï¼š

> â€œPagedAttention kernel wrapper + FlashAttention inner kernelâ€ã€‚

------

## ğŸ§© 5.5 PagedAttention kernel çš„å…³é”®è¾“å…¥è¾“å‡º

è¾“å…¥ï¼š

- `page_table`: æ¯ä¸ª sequence çš„ block_id æ˜ å°„è¡¨ï¼›
- `block_k_ptrs / block_v_ptrs`: å„é¡µåœ¨ GPU KV Pool ä¸­çš„èµ·å§‹åœ°å€ï¼›
- `q`: å½“å‰æ­¥ queryï¼›
- `block_valid_lengths`: æ¯é¡µæœ‰æ•ˆ token æ•°ï¼›
- `attention_mask`: å¯é€‰ï¼ˆå› æœæˆ–paddingï¼‰ã€‚

è¾“å‡ºï¼š

- `attn_out`: å¯¹åº” query çš„æ³¨æ„åŠ›è¾“å‡ºå‘é‡ã€‚

------

## ğŸ§  5.6 åˆ†é¡µåŒ– gather çš„å¹¶è¡Œç­–ç•¥

### çº¿ç¨‹ç²’åº¦

- æ¯ä¸ª warp å¤„ç†ä¸€ä¸ª head çš„ä¸€éƒ¨åˆ†ï¼›
- æ¯ä¸ª CTAï¼ˆthread blockï¼‰å¤„ç†è‹¥å¹²åºåˆ—çš„è‹¥å¹² blockï¼›
- Warp å†…éƒ¨åš tile-level åŠ è½½ä¸ softmaxã€‚

### ä¼˜åŒ–æŠ€å·§

1. **é¡µå†…è¿ç»­è®¿é—®**ï¼šæ¯ä¸ª block çš„ token è¿ç»­ï¼Œä¾¿äº coalesced memory accessã€‚
2. **é¡µé—´æ‰¹é‡ gather**ï¼šé¢„å…ˆç”Ÿæˆ index æ•°ç»„ï¼Œå‡å°‘éšæœºè®¿å­˜ã€‚
3. **å…±äº«å†…å­˜ç¼“å†²**ï¼štile K/V ä¸´æ—¶ç¼“å­˜ã€‚
4. **å¯é‡ç”¨ softmax ä¸­é—´æ€**ï¼šç”¨äº beam search æˆ– speculative decodeã€‚

------

## âš¡ï¸ 5.7 æ€§èƒ½ç“¶é¢ˆä¸ä¼˜åŒ–æ–¹å‘

| æ½œåœ¨ç“¶é¢ˆ         | ä¼˜åŒ–ç­–ç•¥                                  |
| ---------------- | ----------------------------------------- |
| gather éšæœºè®¿é—®  | block_size å›ºå®šã€index list æ‰¹é‡åŠ è½½      |
| kernel å¯åŠ¨å¼€é”€  | é‡‡ç”¨ persistent kernelï¼ˆå¸¸é©»çº¿ç¨‹ï¼‰        |
| å¤šåºåˆ—æ··åˆ batch | åŒæ­¥å¯¹é½ page æ•°é‡ã€grouped kernel launch |
| å†…å­˜å¯¹é½         | block_stride è®¾ä¸º 16/32 å¯¹é½å­—èŠ‚          |
| é‡åŒ– KV          | é™ä½ä¼ è¾“å¸¦å®½ï¼ˆFP16â†’FP8/INT8ï¼‰             |

------

## ğŸ§® 5.8 ä¼ªä»£ç ç¤ºæ„ï¼ˆGPU å†…æ ¸ï¼‰

```cpp
__global__ void paged_attention_kernel(
    const float* q,
    const float* k_pool,
    const float* v_pool,
    const int* page_table,
    const int* seq_lens,
    float* out
) {
    int seq_id = blockIdx.x;
    int head_id = threadIdx.y;
    int layer_id = blockIdx.y;

    // gather per-sequence blocks
    for (int i = 0; i < seq_lens[seq_id]; ++i) {
        int block_id = page_table[seq_id * MAX_BLOCKS + i];
        const float* K = k_pool + block_id * BLOCK_STRIDE;
        const float* V = v_pool + block_id * BLOCK_STRIDE;
        // compute attention(q, K, V)
        flashattention_tile(q, K, V, out);
    }
}
```

> å®é™…å®ç°ä¸­æ˜¯ C++ + CUDA kernelï¼Œèåˆäº† FlashAttention çš„ç®—å­é€»è¾‘ã€‚

------

## ğŸ“ˆ 5.9 æ€§èƒ½å¯¹æ¯”ï¼ˆvLLM Benchmarkï¼‰

| æ¨¡å‹                 | ä¼ ç»Ÿ KVCache | Paged + Flash | ååæå‡ |
| -------------------- | ------------ | ------------- | -------- |
| Llama2-7B (8K ctx)   | ~70 tok/s    | ~210 tok/s    | 3Ã—       |
| Llama2-13B (32K ctx) | OOM / fail   | ~150 tok/s    | âœ…        |
| å¤šè¯·æ±‚å¹¶å‘ 8         | ä¸ç¨³å®š       | å¹³ç¨³å¹¶è¡Œ      | âœ…        |

------

## âœ… å°ç»“

| å…³é”®ç‚¹                    | è¯´æ˜                                  |
| ------------------------- | ------------------------------------- |
| **PagedAttention kernel** | é€šè¿‡é¡µè¡¨æ‰¹é‡ gather K/V               |
| **å›ºå®š block_size**       | ä¿è¯é¡µå†…è¿ç»­ã€GPU è®¿å­˜é«˜æ•ˆ            |
| **FlashAttention ç»“åˆ**   | tile çº§åˆ«æµå¼ softmaxï¼Œä¸é¡µçº§å¸ƒå±€ååŒ |
| **æ€§èƒ½æ ¸å¿ƒ**              | å‡å°‘éšæœºè®¿å­˜ + æ‰¹é‡ç´¢å¼• + å¸¸é©» kernel |
| **æœ¬è´¨**                  | â€œè™šæ‹Ÿå†…å­˜ + tile kernelâ€çš„ GPU åŒ–å®ç° |

------

ä¸‹ä¸€ç« ï¼ˆç¬¬ 6 ç« ï¼‰æˆ‘ä»¬ä¼šä»ç³»ç»Ÿå±‚é¢çœ‹ï¼š

> ğŸ§  **å¹¶å‘ä¸è°ƒåº¦ç­–ç•¥** â€”â€”
>  PagedAttention å¦‚ä½•é…åˆè°ƒåº¦å™¨ï¼ˆschedulerï¼‰å®ç°åŠ¨æ€ batchingã€ä¸Šä¸‹æ–‡åˆå¹¶ï¼ˆprefix mergingï¼‰ã€å¹¶å‘éš”ç¦»ç­‰èƒ½åŠ›ã€‚

æ˜¯å¦ç»§ç»­è¿›å…¥ç¬¬ 6 ç« ï¼Ÿ